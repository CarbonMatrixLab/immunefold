defaults:
  - loss: bayesmvp
  - model: bayesmvp
  - transforms: bayesmvp

# device
gpu_list: [3]

mode: bayesmvp

# optimizer
num_epoch: 1024
warmup_steps: 0
flat_steps: 100000
decay_steps: 2000
learning_rate: 0.0001

# model
restore_esm2_model: ../abdata_2023/esm2/esm2_t36_3B_UR50D.pt

# lora
lora_r: 16
lora_scaling: 1.0

# model align
model_align:
  bias: True

# dataset
batch_size: 1
gradient_accumulation_it: 16
max_seq_len: 512
train_data: ../Tranception/ProteinGym_substitution_sto_files/PTEN_HUMAN_full_11-26-2021_b01.filterd.fasta
    
# output
output_dir: ./studies/bayesmvp_v1

checkpoint_every_step: 1000

verbose: 1
random_seed: 2023
