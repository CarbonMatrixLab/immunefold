defaults:
  - loss: abfold
  - model: esmfold
  - transforms: abfold

# device
gpu_list: [0]

# lora
lora:
 enabled: True
 lora_r_seq: 16
 lora_r_pair: 8
 lora_scaling: 1.0

model_align:
  lora: False
  bias: True
  fft_mode: 'only_evoformer'

# optimizer
num_epoch: 1024
warmup_steps: 0
flat_steps: 20000
decay_steps: 2000
learning_rate: 0.0001
min_lr: 5e-5

# model
restore_model_ckpt: ~/data/esm_ckpt/carbonfold2_base_from_esmfold.ckpt
restore_esm2_model: ~/data/esm_ckpt/esm2_t36_3B_UR50D.pt

is_ig_feature: True
shuffle_multimer_seq: True

# dataset
batch_size: 2
gradient_accumulation_it: 1
max_seq_len: 288
train_name_idx: /home/zhutian/data/tcr_data/idx/train.idx
train_data: /home/zhutian/data/tcr_data/npz/
# train_name_idx: ../data_2023/pdb50_v2/clean_bc40_cluster.idx
# train_data: ../data_2023/pdb50_v2/data/
    
# output
output_dir: ../studies/tcrfold/2024-04-15

checkpoint_every_step: 1000

verbose: 1
random_seed: 2023
